{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;\">Project II - Do you need more signs?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:39:04.710497Z",
     "iopub.status.busy": "2023-03-26T21:39:04.709964Z",
     "iopub.status.idle": "2023-03-26T21:39:12.549925Z",
     "shell.execute_reply": "2023-03-26T21:39:12.549171Z",
     "shell.execute_reply.started": "2023-03-26T21:39:04.710398Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from PIL import Image # Install Pillow -> conda install anaconda::pillow or pip install pillow\n",
    "import os\n",
    "from skimage.io import  imread, imshow # Install scikit-image -> conda install scikit-image or pip install scikit-image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset_path = 'data-students/TRAIN/'\n",
    "test_dataset_path = 'data-students/TEST'\n",
    "\n",
    "predictions_path= 'predictions/'\n",
    "\n",
    "IMG_WIDTH = 75\n",
    "IMG_HEIGHT = 75\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((IMG_WIDTH, IMG_HEIGHT)),transforms.ToTensor()])\n",
    "traffic_signals_dataset = datasets.ImageFolder(root=train_dataset_path, transform=transform)\n",
    "\n",
    "train_idx, valid_idx = train_test_split(\n",
    "    range(len(traffic_signals_dataset)),\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    stratify=traffic_signals_dataset.targets\n",
    ")\n",
    "\n",
    "train_subset = Subset(traffic_signals_dataset, train_idx)\n",
    "valid_subset = Subset(traffic_signals_dataset, valid_idx)\n",
    "\n",
    "train_dataset_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "validation_dataset_loader = DataLoader(valid_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets = traffic_signals_dataset.targets\n",
    "t_targets = {k:0 for k in training_targets}\n",
    "for t in training_targets:\n",
    "    t_targets[t] += 1\n",
    "print('Training class distribution:', t_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:27.311341Z",
     "iopub.status.busy": "2023-03-26T21:51:27.311054Z",
     "iopub.status.idle": "2023-03-26T21:51:27.634985Z",
     "shell.execute_reply": "2023-03-26T21:51:27.633561Z",
     "shell.execute_reply.started": "2023-03-26T21:51:27.311309Z"
    }
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def get_int(self, text):\n",
    "        return [int(c) if c.isdigit() else c for c in re.split('(\\d+)', text)]\n",
    "    \n",
    "    def __init__(self, images_folder, transform=None):\n",
    "        self.images_folder = images_folder\n",
    "        self.image_files = [f for f in os.listdir(images_folder) if os.path.isfile(os.path.join(images_folder, f))]\n",
    "        self.image_files.sort(key=self.get_int)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_folder, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "inference_dataset = TestDataset(images_folder=test_dataset_path, transform=transform)\n",
    "\n",
    "test_dataset_loader = DataLoader(inference_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **iii. Get the Label Mappings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels dictionary is made in order to retrive the class names against the label indices used for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:39.679438Z",
     "iopub.status.busy": "2023-03-26T21:51:39.679162Z",
     "iopub.status.idle": "2023-03-26T21:51:39.686686Z",
     "shell.execute_reply": "2023-03-26T21:51:39.685704Z",
     "shell.execute_reply.started": "2023-03-26T21:51:39.679410Z"
    }
   },
   "outputs": [],
   "source": [
    "### subset version\n",
    "#the_labels = {value for _, value in train_datagen.class_to_idx.items()}\n",
    "labels = {value: key for key, value in traffic_signals_dataset.class_to_idx.items()}\n",
    "print(labels)\n",
    "the_real_labels = {}\n",
    "with open(\"data-students/labels.csv\",\"r\") as label_f:\n",
    "    for line in label_f.readlines()[1:]:\n",
    "        label_value, label_description = line.strip().split(\";\")\n",
    "        the_real_labels[int(label_value)] = label_description \n",
    "\n",
    "print(the_real_labels)\n",
    "\n",
    "print(\"Label Mappings for classes present in the training and validation datasets\\n\")\n",
    "for key, value in labels.items():\n",
    "    print(f\"{key} : {value} - {the_real_labels[int(value)]}\")\n",
    "the_labels_map = {key: value for key, value in traffic_signals_dataset.class_to_idx.items()}\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-03T20:16:06.125325Z",
     "iopub.status.busy": "2022-02-03T20:16:06.124944Z",
     "iopub.status.idle": "2022-02-03T20:16:06.130307Z",
     "shell.execute_reply": "2022-02-03T20:16:06.129222Z",
     "shell.execute_reply.started": "2022-02-03T20:16:06.125223Z"
    }
   },
   "source": [
    "**2. Plotting Sample Training Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-26T21:51:42.955535Z",
     "iopub.status.busy": "2023-03-26T21:51:42.955232Z",
     "iopub.status.idle": "2023-03-26T21:51:45.341504Z",
     "shell.execute_reply": "2023-03-26T21:51:45.340810Z",
     "shell.execute_reply.started": "2023-03-26T21:51:42.955500Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=4, ncols=5, figsize=(12, 9))\n",
    "dataiter = iter(traffic_signals_dataset)\n",
    "idx = 0\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        images, l = next(dataiter)\n",
    "        img = images\n",
    "        label = the_real_labels[int(labels[l])]\n",
    "        ax[i, j].set_title(f\"{label}\")\n",
    "        ax[i, j].imshow(img.permute(1,2,0))\n",
    "        ax[i, j].axis(\"off\")\n",
    "        idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.suptitle(\"Sample Training Images\", fontsize=21)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, img_width, img_height, num_classes):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=5, padding='valid')\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=128)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, padding='valid', bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(num_features=64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, padding='valid', bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(num_features=32)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(32 * self._conv_output_shape(img_width, img_height), 256)  # Assuming square input for simplification\n",
    "        self.fc1 = nn.Linear(1568,256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # L2 regularization is not directly included in layers in PyTorch, \n",
    "        # it's typically added to the optimizer during the training step.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        \n",
    "        x = torch.flatten(x, 1)  # Flatten all dimensions except batch\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def _conv_output_shape(self, img_width, img_height, kernel_size=3, stride=1, padding=0, dilation=1):\n",
    "        h = ((img_height + (2 * padding) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "        w = ((img_width + (2 * padding) - (dilation * (kernel_size - 1)) - 1) / stride) + 1\n",
    "        return int(h/8) * int(w/8)  # Considering three max pooling layers with kernel_size=2, stride=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer,train_dataset_loader, num_epochs=10, device='cpu'):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        cumulative_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_dataset_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #if (batch_idx + 1) % 100 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Step {batch_idx+1}/{len(train_dataset_loader)}, Loss: {loss.item():.4f}')\n",
    "            cumulative_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} average loss: {cumulative_loss/len(train_dataset_loader)}\")\n",
    "    return model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "num_classes = len(labels)\n",
    "print(num_classes)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL = False\n",
    "\n",
    "if TRAIN_MODEL:\n",
    "\n",
    "    num_epochs = 15\n",
    "    model = CustomCNN(IMG_WIDTH, IMG_HEIGHT, num_classes)\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    ccnn = train_model(model, criterion, optimizer, train_dataset_loader, num_epochs, device)\n",
    "    \n",
    "else:\n",
    "    ccnn = torch.load('baseline_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def test_model(model, dataset_loader):\n",
    "    y_real = []\n",
    "    y_pred = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in dataset_loader:\n",
    "            y_real.extend(labels.numpy())\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the model on the {} test images: {} %'.format(total,100 * correct / total))\n",
    "    # Generate the confusion matrix\n",
    "    cm = confusion_matrix(y_real, y_pred)\n",
    "\n",
    "    # Display the confusion matrix\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_model(ccnn, validation_dataset_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = range(1, 311)\n",
    "\n",
    "def model_prediction(model):\n",
    "\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in test_dataset_loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            # Assuming you're interested in the highest probability class\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted_labels.numpy())\n",
    "    print(predictions)\n",
    "    real_labels_predictions = [int(labels[p]) for p in predictions]    \n",
    "    prediction_df = pd.DataFrame({\n",
    "        'ID': image_ids,\n",
    "        'Class': real_labels_predictions\n",
    "    })\n",
    "    prediction_df.to_csv(f'{predictions_path}{model.name}.csv', index=False)\n",
    "\n",
    "def model_prediction(model):\n",
    "    predictions = []\n",
    "    return predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
